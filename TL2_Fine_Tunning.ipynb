{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3mbYV7Sf-vK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Load base model with pretrained weights (no top)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# 2. Freeze all layers initially\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 3. Add custom classifier on top\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')  # Assuming 5 flower classes\n",
        "])\n",
        "\n",
        "# 4. Train classifier only (base model is frozen)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load data\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_gen = datagen.flow_from_directory('flowers/',\n",
        "                                        target_size=(224, 224),\n",
        "                                        batch_size=32,\n",
        "                                        class_mode='categorical',\n",
        "                                        subset='training')\n",
        "\n",
        "val_gen = datagen.flow_from_directory('flowers/',\n",
        "                                      target_size=(224, 224),\n",
        "                                      batch_size=32,\n",
        "                                      class_mode='categorical',\n",
        "                                      subset='validation')\n",
        "\n",
        "# Train only the top classifier\n",
        "model.fit(train_gen, epochs=5, validation_data=val_gen)\n",
        "\n",
        "# 5. Fine-Tune: Unfreeze some top layers of the base model\n",
        "for layer in base_model.layers[-4:]:  # Unfreezing last 4 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "# 6. Recompile with a lower learning rate\n",
        "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 7. Continue training with fine-tuned layers\n",
        "model.fit(train_gen, epochs=5, validation_data=val_gen)\n"
      ]
    }
  ]
}